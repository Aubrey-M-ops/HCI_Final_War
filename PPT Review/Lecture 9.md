# Chapter 9 - Evaluation

> Definition: **<u>Assessment of usability and usefulness</u>** of a system or its components and/or features

## 1. Usability

### 1.1 ä¸€äº›å®šæ€§

1. âŒ Not a **binary** property
2. âŒ Not a **property of an artifact**
   1. âœ… a **relational property** of the **whole user-artifact** system

### 1.2 Aspects of usability 

1. **Learnability**: å­¦çš„å¤šå¿«
2. **Throughput**ï¼š perform taskså¤šå¿«
3. **Flexibility**: userså¯ä»¥åœ¨subsystemsé‡Œåšå¤šå°‘äº‹æƒ…
4. **Attitude**: Usersçš„æ€åº¦å¦‚ä½•

## 2. User Experience 

### 2.1 ä¸€äº›å®šæ€§

- a very nebulous term æ˜¯ä¸ªæ¨¡ç³Šçš„æ¦‚å¿µ
- âŒ Not **first-order** design
  - âœ… It is **second-orde**r design
  - Combined with the user and the context of use

### 2.2 Aspects of user experience 

1. **Desirability**: useræƒ³ç”¨å—
2. **Pleasureability**: useré«˜å…´å—
3. **Engagement**ï¼šSystemæœ‰æ²¡æœ‰attract user (å¯ä»¥ç†è§£ä¸ºç”¨æˆ·çš„å‚ä¸åº¦engageåº¦)
4. **Flow**: users perform tasksçš„ä¸“æ³¨åº¦(does the system fully immerse users in a task)

## 3. Evaluation Techniques

> Definition: Assess the degree of **<u>usability</u>** & <u>**user experience**</u>

### 3.1 Approach(2ä¸ª)

1. #### Analytical å¿«æ·ä¸æ­£å¼

   Perform a **simulation** of how users' tasks will be performed

   **Quick and informal**

2. #### Empirical æ­£å¼ä¸”éº»çƒ¦

   Build a **prototype** and **test it with users**

   éœ€è¦planning, sign up usersç­‰ç­‰

### 3.2 Answer evaluation questions

- **Rarely straightforward**  to answer
- **Rarely** determined by a **quick calculation** 
- time varies(depending on complexity of system)

### 3.3 Evaluation Strategies(2ä¸ª)

ä¸ä¸Šé¢çš„ä¸¤ä¸ªapproachï¼ˆAnalyticalå’Œempiricalï¼‰æ˜¯ç‹¬ç«‹å¼€çš„

1. #### Formative

   - **During design and implementation** process
   - Influence development 

2. #### Summative

   - **After Implementation**
   - Assess proper functioning

### 3.4 Aspects of Evaluation

- **What** evaluation is

  1. usefulness
  2. `Usability` & `User experience`

- **How** to evaluate

  Approach: `analytical` &` empirical `

- **Why** Evaluate

  - To improve design
  - To see if systems meets the need

- **When** to evaluate

  - `Fomative`: throughout
  - `Summative`: at the end

### 3.5 Evaluation Methods

ä¸€èˆ¬éƒ½æ˜¯a collection of approaches

have a mix of analytical / empirical and summative / formative

#### Recording techniques

1. Paper & Pencil
2. Audio Recording
3. Video Recording

#### Analytical Methods

- Cognitive walkthrough (user-artifact centered)
  - Task-specific åˆ†æç”¨æˆ·å¯¹ä»»åŠ¡çš„æ•´ä½“ç†è§£, ç”¨æˆ·æ˜¯å¦çŸ¥é“ä»€ä¹ˆä¸œè¥¿èƒ½æ“ä½œ
- Heuristic evaluation (artifact centered

#### Empirical Methods

- Simple observation
- Think-aloud
- Think-after
- Co-operative Evaluation
- Co-discovery learning

> No perfect method!!!!  

## 4. Heuristic Evaluation 

> This is a form of <u>**analytical evaluation**</u>(å¿«æ·ä¸æ­£å¼)
>
> - Evaluate a system based on a set of principles 
> - é˜¶æ®µï¼šDesign & Evaluation
> - ä¸ºè°æœåŠ¡ï¼špaper prototypes & working systems

### 4.1 What are heuristics

éç¡¬æ€§è§„èŒƒï¼Œä¸€ç§ç»éªŒæ€»ç»“ã€‚ç”¨äºæŒ‡å¯¼å’Œè¯„ä¼°ç”¨æˆ·ç•Œé¢è®¾è®¡ï¼Œç¡®ä¿å¯ç”¨ã€‚

English explanationï¼šGeneral usability guidlines used to evaluate and improve user interface design

### 4.2 ä¼˜ç¼ºç‚¹

#### Pro

- User involvement not required ä¸éœ€è¦ç”¨æˆ·å‚ä¸
- small number of heuristics can catch many common design problems ä»¥å°è§å¤§
- cheap and fast

#### Con

- Real evaluation involves more than a checklist ä¸ç°å®æœ‰å·®è·
- no subtleties of use æ— æ³•è¡¨è¾¾å¾®å¦™çš„ä¸œè¥¿
- Can easily miss what users do and think é—æ¼ç”¨æˆ·æƒ³æ³•

> âš ï¸ dont be naive about their comprehesive effectiveness 
>
> ä¸è¦æŒ‡æœ›ä»–ä»¬æœ‰å…¨é¢çš„æ•ˆæœ

### 4.3 å¸¸è§Heuristicsä¸¾ä¾‹

âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨åæ¡âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨

- 
  Simplify **dialogue** 
- Speak the **usersâ€™ language**
- Minimize the usersâ€™ **memory load**
- Have **consistency**
-  Provide **feedback**
- Provide clearly marked **exits**
- Provide **shortcuts**
-  **Deal with error** in a positive and helpful manner
-  Minimize **user error**
- â—¦Provide help and **documentation**

âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨

> Evaluation  heuristics å°±æ˜¯ä»design conceptes/princinples è¡ç”Ÿè€Œæ¥çš„

### 4.4 Heuristic Evuation

- æ¦‚å¿µï¼š**small set of evaluators** examine the interface **independently** with usability principles (heuristics)

#### ä½¿ç”¨è¿‡ç¨‹ï¼šå°è€Œå¤š

- Individual evaluators ä¼šè¦†ç›–ä¸å…¨

  - ä¸€ä¸ªevaluatoråªä¼šæ‰¾åˆ°35%çš„é—®é¢˜

  - ä¸åŒçš„evaluatoræ‰¾åˆ°ä¸åŒçš„é—®é¢˜

  - Cost-benefit analysis: critical usability ç”¨ more evaluators

- æ¨èæ•°é‡ï¼š5 ï¼ˆæœ€å°‘3ï¼‰
- æ—¶é—´ï¼šé€šå¸¸1-2 hours
- 2éï¼šGo through interface at least twice
  - Macro: å¤§æ¦‚çš„æ„Ÿå—general scope of system
  - Micro: ç¬¬äºŒéfocus on specific interface elements
- Findings are shared after all evaluators finished
  - Ensures independent and unbiased evaluations

#### Record evaluations

- 2 ways: witten report from evaluator /  take notes as the evaluator comments on system
- **List usability problems** and **annotate** them withe specific **principles**
- Does not provide:
  - a systematic way to generate fixes
  - probable quality of redesign (å‡è®¾Redesignä¼šæ€æ ·)
- Fix: based on guidelines 

## 5. Empirical Evaluation  ï¼ˆç»éªŒï¼‰

> åœ¨industryå’Œacademiaéƒ½æœ‰ä½¿ç”¨ï¼

Somebody  doing something in some situation

- Who: humans(individuals/groups)
- What:actions / behaviour/ tasks
- When & where: system/ location

### 5.1 Criteria for good empirical research

- **Generalizability**

  Resultå¯¹åºå¤§ç”¨æˆ·ç¾¤ä½“çš„å¯æ‹“å±•æ€§

- **Precision**

  - Measurement behaviourçš„å‡†ç¡®æ€§
  - å¯¹extraneousæƒ…å†µçš„è€ƒè™‘

- **Realism**

  - The situation you gathered æœ‰å¤šè´´è¿‘ç°å®

### 5.2 *Method - Simple observation

Evaluator observes user performing tasks

- Pro: Easy to do

- Con: Does not give insight into user's decision process. ä¸å…³æ³¨ç”¨æˆ·åšå†³å®šçš„è¿‡ç¨‹

  <img src="/Users/limohan/Library/Application Support/typora-user-images/image-20250410160424701.png" alt="image-20250410160424701" style="zoom:50%;" />

### 5.3 *Method - Think-aloud

> ğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒThe most used evaluation MethodğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“Œ

- æ¦‚å¿µï¼š å‚ä¸è€…åœ¨think / doçš„æ—¶å€™éœ€è¦talk aloud

- âœ¨ This gives insight into what the user is thinking

- Problems

  - Awkward

  - Thinking aloud may alter the way people perform tasks å½±å“åšä»»åŠ¡

  - Hard to talk when concentrating a problem ä¸“æ³¨çš„æ—¶å€™è¯´ä¸äº†è¯

- æ‰€ä»¥ä¹Ÿä¸æ˜¯æ‰€æœ‰æƒ…å†µéƒ½é€‚ç”¨

### 5.4 *Method - Think-after

> Variation of think-aloud

-  Process
  - Record user session (video)
  - Play recording  back to users
  - User watch recording and think aloud
- âœ¨ğŸ‘‰ Userè¡ŒåŠ¨çš„æ—¶å€™å½•è§†é¢‘ï¼Œçœ‹ç€è§†é¢‘å›æ”¾think aloud
  - Overcome think-aloudçš„æ— æ³•åŒæ—¶åšä¸¤ä»¶äº‹çš„é—®é¢˜

### 5.5 *Method - Co-operate Evaluation

Evaluiator and user talk together, äº’ç›¸æé—®

- Evaluatoræé—®æ¯”å¦‚â€œwhy did you do thatâ€ 
- Useræé—®æ¯”å¦‚é‡åˆ°probleméœ€è¦clarification

å¥½å¤„ï¼š

- **Less constrained** than think-aloud
- User can **criticize** the system 
- Evaluator can **clarify confusion**

âš ï¸ Evaluatorå¯èƒ½ä¼šè¿‡åº¦å½±å“user (overly influence the user)

### 5.6 *Method - Co-discovery learning

Two people work together on a task

> Between two `users`!

It removes awkwardness

## 6. Examples and case studies

### 6.1 Case Study 1

**<u>Task</u>**: Develop concept maps

**Goal**: How does the tool support the development of concept maps

- Explore shapes
- Make sense of relationships among them
- Determine how they are derived from each other 

<img src="/Users/limohan/Library/Application Support/typora-user-images/image-20250410221711505.png" alt="image-20250410221711505" style="zoom:50%;" />

**3 ways to interact** (interfaces )

1. Stacked
2. Distributed
3. Coupled

**Study Design**

1. Mixed methods are combined 
2. Multiple types of data-collection instruments
3. Multi-Method was used to cross validate(äº¤å‰éªŒè¯)
4. Compare 3 groups, each group interacting with one of 3 interfaces

**Participants**

36 undergraduate computer science and engineering students

None of the subjects previously used the tool æ²¡äººä¹‹å‰ç”¨è¿‡

**Procedure**

<img src="/Users/limohan/Library/Application Support/typora-user-images/image-20250410224453456.png" alt="image-20250410224453456" style="zoom:50%;" />

**Data Sources**

1. Achievement Results
2. Video Transcripts
3. Interview Transcripts
4. Direct Observation

**Results**

<img src="/Users/limohan/Library/Application Support/typora-user-images/image-20250410224658997.png" alt="image-20250410224658997" style="zoom:50%;" />

**Conclusion**

1. Transitional processes ä¸æ˜“ç†è§£
2. Computer toolså¯ä»¥separate it
3. By placing distributed and stacked interfaces side by side, userså¯ä»¥control each dimension
4. ä¹Ÿä¸ºå…¶ä»–çš„studyæä¾›implications

### Case Study 2

å’ŒCase study1ç±»ä¼¼ï¼Œåœ¨ppté‡Œ64é¡µ

ä¹Ÿä¸åœ¨pptæœ€åçš„summaryé‡Œï¼Œ

åº”è¯¥åªæ˜¯è€å¸ˆä¸¾äº†ä¸¤ä¸ªä»–åšè¿‡çš„study ç‰¹åˆ«å…·ä½“é‚£ç§ï¼Œä¸æ˜¯é‡ç‚¹ã€‚
